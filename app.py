
import os, uuid
from flask import Flask, render_template, request, jsonify, make_response
from openai import AzureOpenAI

app = Flask(__name__)

# ===== Azure OpenAI client =====
client = AzureOpenAI(
    api_key=os.getenv("AZURE_API_KEY"),
    api_version="2024-05-01-preview",
    azure_endpoint=os.getenv("ENDPOINT")
)
MODEL = os.getenv("AZURE_DEPLOYMENT", "gpt-4o")

# ===== Mem√≥ria simples em RAM por sess√£o =====
SESSIONS = {}  # sid -> { 'profile': 'academico|acolhedora|desafiadora', 'next_block': int, 'user_text': str }

BASE_RULES = (
    "Voc√™ √© um agente que ajuda jovens do Ismart a ensaiar sua apresenta√ß√£o de Projeto de Vida para uma banca simulada. "
    "Siga estritamente as regras:
"
    "1) Nunca entregue tudo de uma vez.
"
    "2) Sempre responda em blocos numerados (Bloco 1, Bloco 2, ...), cada um focado em um aspecto (estrutura, clareza, emo√ß√£o, impacto, evid√™ncias, etc.).
"
    "3) Ao final de cada bloco, SEMPRE pergunte: 'Entendeu at√© aqui? Quer que eu continue ou aprofunde algum ponto?'
"
    "4) Pare ap√≥s UM √öNICO BLOCO. Aguarde a resposta do aluno para seguir.
"
    "5) Alinhe-se aos princ√≠pios do Ismart: autoconhecimento, protagonismo, resili√™ncia, √©tica, transforma√ß√£o social e mentalidade de crescimento. "
    "Quando √∫til, conecte ao Projeto Pedag√≥gico do Ismart, ao Roteiro de Projeto de Vida e ao livro 'Sonho Grande' (sem citar nomes espec√≠ficos)."
)

PROFILE_TONES = {
    "academico": (
        "Perfil: Rigor Acad√™mico. Tom formal, cr√≠tico e respeitoso. Valorize clareza conceitual, consist√™ncia l√≥gica e uso de evid√™ncias. "
        "Conecte perguntas √†s compet√™ncias de Aprendizagem e Curiosidade. Finalize cada bloco com uma sugest√£o pr√°tica."
    ),
    "acolhedora": (
        "Perfil: Acolhedora. Tom emp√°tico, motivador e construtivo. Valorize conquistas, fortale√ßa a autoestima e reconhe√ßa o esfor√ßo. "
        "Conecte perguntas a Inclus√£o, Pertencimento, Comunidade, Resili√™ncia e Bem-Estar. Termine com refor√ßo de confian√ßa."
    ),
    "desafiadora": (
        "Perfil: Desafiadora. Tom firme e provocador, sempre respeitoso. Questione argumentos, levante hip√≥teses contr√°rias e pe√ßa justificativas s√≥lidas. "
        "Conecte a Autonomia e Protagonismo, e mostre pontos de fragilidade para reflex√£o."
    ),
}

def get_sid(resp=None):
    sid = request.cookies.get("sid")
    if not sid:
        sid = uuid.uuid4().hex
        if resp is None:
            resp = make_response()
        resp.set_cookie("sid", sid, httponly=False, samesite="Lax")
    return sid, resp

@app.route("/")
def index():
    resp = make_response(render_template("index.html"))
    # garante cookie de sess√£o simples
    sid, resp = get_sid(resp)
    if sid not in SESSIONS:
        SESSIONS[sid] = {"profile": None, "next_block": 1, "user_text": ""}
    return resp

@app.route("/select_profile", methods=["POST"])
def select_profile():
    sid = request.cookies.get("sid")
    data = request.get_json(force=True)
    profile = data.get("profile")
    if profile not in PROFILE_TONES:
        return jsonify({"ok": False, "error": "Perfil inv√°lido"}), 400
    if sid not in SESSIONS:
        SESSIONS[sid] = {"profile": profile, "next_block": 1, "user_text": ""}
    else:
        SESSIONS[sid]["profile"] = profile
        SESSIONS[sid]["next_block"] = 1
    return jsonify({"ok": True})

@app.route("/chat", methods=["POST"])
def chat():
    sid = request.cookies.get("sid")
    if sid not in SESSIONS:
        SESSIONS[sid] = {"profile": None, "next_block": 1, "user_text": ""}
    state = SESSIONS[sid]

    data = request.get_json(force=True)
    user_msg = (data.get("message") or "").strip()

    # Caso n√£o tenha perfil escolhido ainda
    if not state["profile"]:
        welcome = (
            "Ol√°! Bem-vindo ao seu treino de Projeto de Vida no Ismart. "
            "Escolha a banca para treinar hoje: 1) Rigor Acad√™mico, 2) Acolhedora, 3) Desafiadora. "
            "Digite 1, 2 ou 3 para come√ßarmos."
        )
        return jsonify({"reply": welcome})

    # Detecta 'continuar' vs novo texto
    low = user_msg.lower()
    is_continue = low in {"sim", "pode continuar", "pode seguir", "continuar", "segue", "ok", "sim, pode continuar", "s", "vai"}

    # Se o aluno enviou um texto muito curto (e n√£o for 'continuar'), pedimos para colar o conte√∫do
    if not is_continue and len(user_msg) < 12 and not state["user_text"]:
        return jsonify({"reply": "Pode colar o trecho da sua apresenta√ß√£o para eu come√ßar o Bloco 1? üòä"})

    # Se √© um novo texto longo, registramos como contexto e reiniciamos para o Bloco 1
    if len(user_msg) >= 12 and not is_continue:
        state["user_text"] = user_msg
        state["next_block"] = 1

    # Monta instru√ß√µes
    block_no = state["next_block"]
    profile_key = state["profile"]
    tone = PROFILE_TONES.get(profile_key, PROFILE_TONES["acolhedora"])

    system_prompt = (
        BASE_RULES + " "
        + tone + " "
        + f"RESPONDA AGORA APENAS O 'Bloco {block_no}'. Termine com a pergunta de checagem e PARE."
    )

    # Constr√≥i a entrada do usu√°rio para o modelo
    if state["user_text"]:
        user_payload = (
            f"Perfil selecionado: {profile_key}. "
            f"Este √© o texto do aluno para an√°lise (contexto cont√≠nuo):

{state['user_text']}

"
            f"Continue a partir do Bloco {block_no}. Responda somente UM bloco, finalize com a checagem e pare."
        )
    else:
        user_payload = (
            f"Perfil selecionado: {profile_key}. O aluno ainda n√£o colou um texto longo. "
            f"Inicie com Bloco {block_no} focando em estrutura/clareza para ajudar a organizar a apresenta√ß√£o. "
            f"Responda UM bloco, finalize com a checagem e pare."
        )

    # Chamada ao modelo
    try:
        resp = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_payload},
            ],
            temperature=0.7,
            max_tokens=600,
        )
        reply = resp.choices[0].message.content
    except Exception as e:
        reply = f"Erro ao gerar resposta: {e}"

    # Prepara pr√≥ximo passo: s√≥ avan√ßa o contador ap√≥s enviar um bloco
    state["next_block"] = block_no + 1
    return jsonify({"reply": reply})
